1.最低500ms的时间间隔对数据流进行处理,处理的延迟可以达到大约1s,是一个准实时处理系统.
2.容错:具有极高效的错误处理和恢复能力
3.和SparkSQL、MLlib、GraphX无缝集成
4.数据源Socket/Kafka/Flume/HDFS/ZeroMQ/Twitter/MQTT等
5.输出源HDFS/Databases/Dashboards等[print/saveAsObjectFile/saveAsTextFiles/saveAsHadoopFiles/foreachRDD],foreachRDD是对DStream中的每个RDD进行操作

原理:
    a.把输入的数据流用时间切片的方式把数据分成一个个小小的Batch,然后将这些小的Batch交给Spark引擎处理
    b.核心就是DStream[离散数据流],就是一系列RDD的集合,随着时间的流逝RDD不断产生,产生的RDD都会被DStream管理和计算
    c.主要运行场景:
        无状态操作:只是计算当前时间切片[Batch]的内容
        有状态操作:[updateStateByKey],不断的把当前和历史的时间切片的RDD累加计算,随着时间的流逝,计算的数据规模越来越大
        window操作:针对特定时间段并以特定时间间隔为单位进行的滑动操作,例如在以1秒钟为时间切片的情况下,统计最近10分钟内产生的数据,并每隔2分钟更新一次
    


优化:
    1.窗口函数,如果slideTimeInterval < windowLength,那么后面的窗口统计和前一个窗口统计有重合的计算部分,进行优化[eg:val wordCounts = words.map(x=>(x,1)).reduceByKeyAndWindow(_+_,_-_,Seconds(5s),Seconds(1s))]