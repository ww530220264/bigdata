## SparkConf

+ 从System Properties中加载所有spark.*的属性【可配置是否需要加载】
+ 直接在SparkConf对象中设置的参数的优先级大于System Properties中配置的属性
+ 当SparkConf对象传递给Spark之后，它将被拷贝并且在运行期不支持修改配置

## SparkContext

+ Spark功能的主要入口点，代表了一个通往集群的连接。可以被用来创建RDD，Accumulators、Broadcast Varibales
+ 一个JVM只能有一个活跃的SparkContext。在创建新的之前必须把活跃的停掉

+ 根据SparkConf创建SparkContext

+ 私有变量

  + 监听器总线
  + SparkEnv
  + 状态跟踪器
  + 进度条
  + ui
  + 调度器后端
  + 任务调度器
  + 心跳接收器
  + dagScheduler
  + 上下文清理器
  + 跟踪所有被缓存的RDD
  + executorEnvs【用来传递给Executors的环境变量】
  + checkpointDir

+ 设置Driver address和port【默认0：端口随机】

+ 获取【spark.jar】属性配置的jar文件，Spark内部会通过文件服务器分发这些文件，**如果在【YARN】模式下，返回一个空列表，因为YARN有自己的分发jar文件的机制**

+ 获取【spark.files】属性配置的文件

+ 获取【spark.eventLog.dir】配置属性，保存事件日志的目录

+ 获取【spark.eventLog.compress】属性，压缩事件日志的压缩器

+ 初始化【LiveListenerBus】对象，暂未启动

+ 初始化【AppStatusStore】对象，并将SppStatusListener放入监听器总线中

+ 创建Spark执行环境SparkEnv，也就是Driver执行环境

  + 创建Rpc环境

    + 创建消息分发器【dispatcher】

      ```
      endpoints: [String, EndpointData]
      endpointRefs: [RpcEndpoint, RpcEndpointRef]
      //跟踪那些消息盒子中包含消息的接收器
      receivers = new LinkedBlockingQueue[EndpointData]
      ```

  + 启动sparkDriver服务

  + 初始化【BroadcastManager】

  + 初始化【MapOutputTrackerMaster】并启动一个线程池【map-output-dispatcher】来处理map输出状态的请求，然后注册到distpatcher中

  + 初始化【ShuffleManager】

  + 初始化【MemoryManager】

  + 创建【BlockManagerMaster】并注册到dispatcher

  + 创建【BlockManager】，暂未初始化

    + 创建DiskBlockManager
    + 创建MemStore
    + 注册BlockManagerSlaveEndpoint到dispatcher中

  + 创建Driver端【MetricsSystem】,暂未启动

  + 创建Driver【OutputCommitCoordinator】

    + 注册到dispatcher
    + 客户端后面也会Executors 端的OutputCommitCoordinator，然后会引用Driver端的OutputCommitCoordinatorEndpoint，因此Executors端的commit output请求会转交给Driver的OutputCommitCoordinator

  + 实例化上述需要的对象后，实例化SparkEnv对象

  + 创建Driver端临时目录，当SparkContext停止的时候，该临时目录将被删除

+ 创建SparkUI,并启动

+ 完善【ExecutorEnvs】环境变量

+ 注册【HeartBeatReceiver】到dispatcher

+ 创建并启动【TaskScheduler】，暂未启动

  + 创建【TaskScheduler】和【SchedulerBackend】

+ 创建DAGScheduler