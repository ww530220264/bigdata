# JAVA基础

# MYSQL

# REDIS

## String

> **SDS动态字符串:**预分配冗余空间减少内存的频繁分配.字符串长度小于1M时,扩容是加倍现有空间,大于1M时,扩容时只会扩容1M的空间,字符串的最大长度为512M

> **结构:** free,len,buf[]

> **操作:** get、set、mget、mset、setex key expiretime value、expire key expiretime、exists key

## List

> **操作:** lpush、lpop、rpush、rpop、lindex、lrange、ltrim、llen

## Hash

> **操作:** hset、hget、hgetall、hlen、hmset、hincrby key subkey 1

## Set

> **操作:** sadd、smembers、sismember、spop、scard

## ZSet

> **操作:** 
>
> zadd key score value、
>
> zrange key 0 -1、
>
> zrevrange key 0 -1、
>
> zscore key value、
>
> zrank key value、
>
> zrangebyscore key score1 score2、
>
> zrangebyscore key score1 socre2 withscores、
>
> zrem key value

## HyperLogLog

## BitMap

## BloomFilter

# 数据结构

# 常见算法

## 一致性hash

> **概念:**当(缓存)集群中节点退出或新增节点时,使缓存受到影响的范围最小.使用0-2^31-1当做一个环,根据各个节点的主机名或ip将使用相应的算法将各个节点映射到这个环上,当客户端使用key访问缓存时,根据对应的算法将key映射到这个环上,取距离key的顺时针最近的一个节点作为访问这个key的数据所在的缓存节点.
>
> **节点退出:**当某个缓存节点意外退出时,之前缓存在该节点上数据失效,其他节点上的缓存仍然有效,当再次访问该节点上的key时,将会定位到这个节点的下一个缓存节点
>
> **新增节点:**当新增一个节点时,之前定位到这个新增节点顺时针方向的下一个节点上的key将会定位到这个新增节点上,不影响其他的节点
>
> **虚拟节点:**当集群中节点个数很少时,可以给每个物理节点创建多个虚拟节点映射到环上,可以让缓存数据更均匀的分布在少数节点上,不过需要维护物理节点和虚拟节点的映射关系

# FLUME

# KAFKA

## 角色

+ Broker
+ Borker Controller

# HDFS

## 角色

+ NameNode
+ SecondaryNameNode
+ DataNode
+ JournalNode

# YARN

## 角色

+ ResourceManager

+ NodeManager

+ ApplicationMaster--MRAppMaster

+ Scheduler

## 调度策略

### FIFOScheduler--先进先出调度器

先进先出调度策略,如果一个大的Job先进入队列,那么这个Job先运行,后续提交的小的Job如果当前资源不够的话则需要等待大的Job资源释放才能被调度运行,这种策略不能有效的共享集群资源,如果集群当前资源不够使用,Job需要等待

### CapacityScheduler--容量调度器

容量调度器:允许多个组织共享集群资源,每个组织可以获取集群的一部分资源,通过给每个组织分配专门的队列,再为每个队列分配一定的集群资源,这样集群资源就可以通过分配队列的方式给多个组织提供服务,除此之外,队列还可以垂直划分,然后每个组织中的每个成员就可以共享这个队列资源了,在一个队列内部,采用的是FIFO的调度策略

可以使用一个专门的队列来运行小任务,但是为小任务设置一个专门的队列会预先占用一定的集群资源,这就导致大任务的执行时间落后于使用FIFO调度策略的执行时间

```xml
<property>
	<name>yarn.resourcemanager.shceduler.class</name>
    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
</property>
<!-- 队列设置 capacity-scheduler.xml -->
#定义root队列的子队列prod和dev
<property>
  <name>yarn.scheduler.capacity.root.queues</name>
  <value>prod,dev</value>
</property>
#定义dev队列的子队列eng和science
<property>
  <name>yarn.scheduler.capacity.root.dev.queues</name>
  <value>eng,science</value>
</property>
#定义prod队列的容量
<property>
    <name>yarn.scheduler.capacity.root.prod.capacity</name>
    <value>40</value>
</property>
#定义dev队列的容量
<property>
    <name>yarn.scheduler.capacity.root.dev.capacity</name>
    <value>60</value>
</property>
#定义dev队列的最大容量
<property>
    <name>yarn.scheduler.capacity.root.dev.maximum-capacity</name>
    <value>75</value>
</property>
#定义dev的子队列eng的容量
<property>
    <name>yarn.scheduler.capacity.root.dev.eng.capacity</name>
    <value>50</value>
</property>
#定义dev的子队列science的容量
<property>
    <name>yarn.scheduler.capacity.root.dev.science.capacity</name>
    <value>50</value>
</property>
```

### FairShceduler--公平调度器

公平调度策略:不需要预先占用集群资源,FIFO会为所有运行的Job动态调整系统资源,需要注意的是,在第二个任务提交后需要一定的时间获取集群资源,因为它需要正在运行的Job释放一部分集群资源,小任务执行完成后也会释放占用的Container,最后的结果是集群资源得到了充分利用,同时小任务也能较为及时的完成.

每个队列内部仍然可用不同的调度策略

```xml
<property>
  <name>yarn.resourcemanager.scheduler.class</name>
  <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
</property>
<!-- fair-scheduler.xml -->
<?xml version="1.0"?>
<allocations>
#prod队列的配置
  <queue name="prod">
    <minResources>10000 mb,0vcores</minResources>
    <maxResources>90000 mb,0vcores</maxResources>
    <weight>40</weight>
    <schedulingPolicy>fifo</schedulingPolicy>
  </queue>
#dev队列的配置
  <queue name="dev">
    <minResources>10000 mb,0vcores</minResources>
    <maxResources>90000 mb,0vcores</maxResources>
    <weight>40</weight>
    <schedulingPolicy>fair</schedulingPolicy>
    <queue name="eng" />
    <queue name="science" />
  </queue>
#队列放置策略 
  <queuePlacementPolicy>
    <rule name="specified" create="false" />
    <rule name="primaryGroup" create="false" />
    <rule name="default" queue="dev.eng"/>
  </queuePlacementPolicy>
</allocations>
```

### Preemption--抢占

当一个Job提交的一个繁忙集群的空队列时,Job并不会马上执行,而是阻塞直到正在运行的Job释放资源,为了使提交的Job的执行时间更具有预测性(可以设置等待的超时时间),Fair调度器支持抢占.

抢占就是允许调度器杀掉占用超过其应占份额资源队列的Containers,这些Containers的资源便可以分配到应该享有这些份额资源的队列中.需要注意的是,抢占会降低集群的执行效率,因为被终止的Containers需要被重新执行.

可以通过设置一个全局的参数yarn.scheduler.fair.preemption=true来启用抢占功能,此外,还有两个参数用来控制抢占的过期时间(这两个参数默认没有配置,需要至少配置一个来允许抢占Container)

minimum.share.preemption.timeout

fair.share.preemption.timeout

如果队列在minimum.share.preemption.timeout指定的时间内未获得最小的资源保障,调度器就会抢占Containers,我们可以通过配置文件中的顶级元素为所有队列配置这个超时时间,我们还可以在元素内部配置元素来为某个队列指定超时时间

### Mapreduce--相关参数配置

规整因子

```
yarn.shceduler.increment-allocation-mb--默认1024m
yarn.scheduler.increment-allocation-vcores--默认1core
```

NodeManager内存容量配置

NodeManager内存容量配置

```
yarn.nodemanager.resource.memory-mb
```

NodeManager虚拟内存率配置,默认2.1

```
yarn.nodemanager.vmem-pmem-ratio
```

Container容器最小申请内存大小

```
yarn.scheculer.minimum-allocation-mb
```

Container容器最大申请内存大小

```
yarn.scheculer.maximum-allocation-mb
```

MapTask Container容器内存大小

```
mapreduce.map.memory.mb
```

ReduceTask Container容器内存大小

```
mapreduce.reduce.memory.mb
```

Map任务的Jvm参数--需要小于MapContainer容器的内存大小

```
mapreduce.map.java.opts-- -Xms -Xmx
```

Reduce任务的Jvm参数--需要小于ReduceContainer容器的内存大小

```
mapreduce.reduce.java.opts-- -Xms -Xmx
```

# HIVE

# HBASE

# SPARK

# FLINK

## 执行流程

### Stream

+ StreamProgram: 程序员定义的程序流程,

  + transformation(s)
  + operator(s)

+ 方法: StreamGraph <= StreamGraphGenerator.generate(env, transformations)

  ```java
  // 1.
  StreamGraphGenerator(env).generateInternal(transformations);
  // 2.
  private StreamGraph generateInternal(List<StreamTransformation<?>> transformations) {
  	for (StreamTransformation<?> transformation: transformations) {
  			transform(transformation);
  	}
  	return streamGraph;
  }
  ```

+ StreamGraph

  + StreamNode
    + 根据transformation创建对应的StreamNode
  + StreamEdge
    + 然后根据transformation及transformation的输入(inputs)创建相应的StreamEdge

+ JobGraph: 集群客户端(client)在submitJob之前根据StreamGraph获取JobGraph

  ```java
  // 1.compiledPlan也就是StreamGraph
  JobGraph job = getJobGraph(flinkConfig, compiledPlan, libraries, classpaths, savepointSettings);
  // 2.StreamingJobGraphGenerator创建StreamGraph
  JobGraph job = StreamingJobGraphGenerator.createJobGraph(this, jobID);
  // 3.client提交JobGraph到JobManager
  return submitJob(job, classLoader);
  ```
  
+ 设置调度模式
  
+ 为每个顶点设置确定的hash值
  
+ 判断两个StreamNode是否可链接
  
  + 下游节点只有一个输入StreamEdge
  + 两个节点拥有相同的共享slot组
  + 上游节点的链接策略是HEAD或者是ALWAYS,下游节点的链接策略是ALWAYS
  + 上游节点和下游节点并行度相同
  + 这两个节点中间的StreamEdge的分区器是ForwardPartitioner类型
  + StreamGraph是可链接的
  
+ 从source创建task chains,如果StreamNode是task chain的头结点的话就创建一个JobVertex,不是头结点的StreamNode就创建一个StreamConfig
  
+ 上游JobVertex和下游JobVertex连接,上游JobVertex创建中间结果集,然后通过中间结果集创建JobEdge进行连接.
  
  ```
  upstreamJobVertex---> produce 中间结果集---> JobEdge作为中间结果集的消费者并作为下游的输入---> downstreamJobVertex
  ```
  
+ 给相应的JobVertex设置共享slot和co-location group
  
  + 配置checkpoint相关内容
  
  + 添加用户手动指定的内容
  
+ 集群客户端将JobGraph提交到JobManager,在JobManager端构建ExecutionGraph

  + 创建ExecutionJobVertex: 根据JobVertex创建对应的ExecutionJobVertex
  + 创建ExecutionVertex: 根据ExecutionJobVertex以及相应的并行度创建相同数量的ExecutionVertex
  + 将ExecutionVertex与上游中间结果集的分区使用ExecutionEdge进行连接

+ ExecutionGraph调度执行

  ```java
  ExecutionGraph.scheduleForExecution()
  ```

  + 遍历ExecutionJobVertex,进行资源分配

    + ```java
      ejv.allocateResourcesForAll(...)
      ```

    + 遍历ExecutionJobVertex中的每个ExecutionVertex,进行slot分配

      + ```java
        exe.allocateAndAssignSlotForExecution(...)
        ```

  + 分配完成后部署每个Execution

    + ```java
      exe.deploy()
      ```

    + 创建每个ExecutionVertex的部署描述信息,并提交到TaskManager

      + ```java
        // 1
        val deployment = ExecutionVertex.createDeploymentDescriptor(...)
        // 2.根据分配的slot获取对应的TaskMangerGateway
        val taskManagerGateway = slot.getTaskManagerGateway()
        // 3.提交到TaskManager
        taskManagerGateway.submitTask(deployment)
        ```

  + TaskManager接收到JobManager发送来的SubmitTask消息后,进行Task任务的创建,并启动线程运行Task

    + ```java
      // 1.从Blob Store下载数据到tdd对象中
      tdd.loadBigData(blobCache.getPermanentBlobService); 
      // 2.获取job信息
      tdd.getSerializedJobInformation.deserializeValue(getClass.getClassLoader)
      // 3.获取task信息
      tdd.getSerializedTaskInformation.deserializeValue(getClass.getClassLoader)
      // 4.添加task相关度量指标
      // 5.创建TaskInputSplitProvider
      // 6.创建Task状态管理器
      // 7.创建Task对象
      // 8.启动Task-->Runnable,执行Task对象的run()方法
      task.startTaskThread()
      ```

    + ```java
      // 1.
      FileSystemSafetyNet.initializeSafetyNetForThread();
      // 2.
      blobService.getPermanentBlobService().registerJob(jobId);
      // 3.给ResultPartition分配BufferPool并注册到ResultPartitionManager
      // 3.给InputGate分配BufferPoop
      network.registerTask(this);
      // 4.创建task的kvState注册中心
      network.createKvStateTaskRegistry(jobId, getJobVertexId());
      // 5.创建运行时环境
      Environment env = new RuntimeEnvironment(...)
      // 6.创建具体的可执行的Task实例
      invokable = loadAndInstantiateInvokable(userCodeClassLoader, nameOfInvokableClass, env);
      // 7.执行实例的invoke方法
      invokable.invoke();
      ```


## 角色

### JobManager

+ 接收Flink Job
+ 调度tasks
+ 收集job状态
+ 管理task managers
+ 接收消息并处理
  + RegisterTaskManager
  + SubmitJob
  + CancelJob
  + UpdateTaskExecutionState
  + RequestNextInputSplit
  + JobStatusChanged

## 窗口操作

Evictor

> 在窗口触发操作之后,在实际计算之前执行,因为不能使用预聚合操作,因此会显著降低窗口性能

# Machine Learning

# AI

## 相关概念

+ 有监督学习:有标记信息[supervised learning]

  + 分类任务:预测的是离散值
    + 二分类[binary classification]
      + 分为正类和反类[或称为负类]
    + 多分类[multi-class classification]
  + 回归任务:预测的是连续值

+ 无监督学习:无标记信息[unsupervised learning]

  + 聚类[clustering]

+ 泛化能力[generalization]:学得模型适用于新样本的能力

+ 归纳学习:从特殊到一般的泛化,即从具体的事实归结出一般性规律

  + 机器学习属于归纳学习
  + 广义:从样例中学习
  + 狭义:从训练数据中学的概念[concept],因此亦称为概念学习
    + 比如最基本的布尔概念学习,即对"是","不是"这样的可表示为0/1布尔值的目标概念的学习

+ 演绎学习:从一般到特殊化的特化过程,即从基础原理推演出具体情况

+ 归纳偏好:学习算法自身在一个可能很庞大的假设空间中对假设进行选择的启发式或价值观

  + 奥卡姆剃刀:引导算法确立正确的偏好
    + 若有多个假设与观察一致,那么选择最简单的那个

  

  